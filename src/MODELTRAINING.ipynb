{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = r\"E:\\2nd year\\Winter project\\Thyroid Performance Analysis\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\dwija\\OneDrive\\Thyroid-Performance-Analysis\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_test = pd.read_csv(data_path+r'\\anntest.CSV')\n",
    "ann_train = pd.read_csv(data_path+r'\\anntrain.CSV')\n",
    "hyper_test = pd.read_csv(data_path+r'\\hyperTest.CSV')\n",
    "hyper_train = pd.read_csv(data_path+r'\\hyperTrain.CSV')\n",
    "hypo_test = pd.read_csv(data_path+r'\\hypoTest.CSV')\n",
    "hypo_train = pd.read_csv(data_path+r'\\hypoTrain.CSV')\n",
    "all_hypo_train = pd.read_csv(data_path+r'\\hypothyroid.csv')\n",
    "euthyroid = pd.read_csv(data_path+r'\\sick-euthyroid.CSV')\n",
    "thyroid0387 = pd.read_csv(data_path+r'\\thyroid0387EDIT.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'ann test': ann_test,\n",
    "    'ann train': ann_train,\n",
    "    'hyper test': hyper_test,\n",
    "    'hyper train': hyper_train,\n",
    "    'hypo test': hypo_test,\n",
    "    'hypo train': hypo_train,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_hyper_data ={    'hyper test': hyper_test,\n",
    "    'hyper train': hyper_train,\n",
    "    'hypo test': hypo_test,\n",
    "    'hypo train': hypo_train,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_train = ann_train.drop_duplicates()\n",
    "ann_test = ann_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in hypo_hyper_data.items():\n",
    "        df.drop(\"ID\", axis=1, inplace=True)\n",
    "        df.drop(\"referral_source\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_test['Target'] = hyper_test['Target'].replace([\"hyperthyroid\", \"T3_toxic\", \"goitre\", \"secondary_toxic\"], \"hyperthyroid\")\n",
    "hyper_train['Target'] = hyper_train['Target'].replace([\"hyperthyroid\", \"T3_toxic\", \"goitre\", \"secondary_toxic\"], \"hyperthyroid\")\n",
    "hypo_test['Target'] = hypo_test['Target'].replace([\"hypothyroid\", \"primary_hypothyroid\", \"compensated_hypothyroid\", \"secondary_hypothyroid\"],\"hypothyroid\")\n",
    "hypo_train['Target'] = hypo_train['Target'].replace([\"hypothyroid\", \"primary_hypothyroid\", \"compensated_hypothyroid\", \"secondary_hypothyroid\"],\"hypothyroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.concat([hyper_test,hyper_train,hypo_test,hypo_train], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['sex'] = Dataset['sex'].replace({'M': 0, 'F': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop(['TBG', 'TBG_measured','sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          0\n",
       "on_thyroxine                 0\n",
       "query_on_thyroxine           0\n",
       "on_antithyroid_medication    0\n",
       "sick                         0\n",
       "pregnant                     0\n",
       "thyroid_surgery              0\n",
       "I131_treatment               0\n",
       "query_hypothyroid            0\n",
       "query_hyperthyroid           0\n",
       "lithium                      0\n",
       "goitre                       0\n",
       "tumor                        0\n",
       "hypopituitary                0\n",
       "psych                        0\n",
       "TSH_measured                 0\n",
       "TSH                          0\n",
       "T3_measured                  0\n",
       "T3                           0\n",
       "TT4_measured                 0\n",
       "TT4                          0\n",
       "T4U_measured                 0\n",
       "T4U                          0\n",
       "FTI_measured                 0\n",
       "FTI                          0\n",
       "Target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.dropna(axis = 0, thresh = 22, inplace = True)\n",
    "Dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          object\n",
       "on_thyroxine                  int64\n",
       "query_on_thyroxine            int64\n",
       "on_antithyroid_medication     int64\n",
       "sick                          int64\n",
       "pregnant                      int64\n",
       "thyroid_surgery               int64\n",
       "I131_treatment                int64\n",
       "query_hypothyroid             int64\n",
       "query_hyperthyroid            int64\n",
       "lithium                       int64\n",
       "goitre                        int64\n",
       "tumor                         int64\n",
       "hypopituitary                 int64\n",
       "psych                         int64\n",
       "TSH_measured                  int64\n",
       "TSH                          object\n",
       "T3_measured                   int64\n",
       "T3                           object\n",
       "TT4_measured                  int64\n",
       "TT4                          object\n",
       "T4U_measured                  int64\n",
       "T4U                          object\n",
       "FTI_measured                  int64\n",
       "FTI                          object\n",
       "Target                        int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset = Dataset.replace({\"t\":1,\"f\":0, \"y\":1, \"n\":0, \"hypothyroid\":1, \"negative\":0,\"hyperthyroid\":2, \"F\":1, \"M\":0})\n",
    "display(Dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          float64\n",
       "on_thyroxine                   int64\n",
       "query_on_thyroxine             int64\n",
       "on_antithyroid_medication      int64\n",
       "sick                           int64\n",
       "pregnant                       int64\n",
       "thyroid_surgery                int64\n",
       "I131_treatment                 int64\n",
       "query_hypothyroid              int64\n",
       "query_hyperthyroid             int64\n",
       "lithium                        int64\n",
       "goitre                         int64\n",
       "tumor                          int64\n",
       "hypopituitary                  int64\n",
       "psych                          int64\n",
       "TSH_measured                   int64\n",
       "TSH                          float64\n",
       "T3_measured                    int64\n",
       "T3                           float64\n",
       "TT4_measured                   int64\n",
       "TT4                          float64\n",
       "T4U_measured                   int64\n",
       "T4U                          float64\n",
       "FTI_measured                   int64\n",
       "FTI                          float64\n",
       "Target                         int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = Dataset.columns[Dataset.dtypes.eq('object')]\n",
    "Dataset[cols] = Dataset[cols].apply(pd.to_numeric, errors='coerce')\n",
    "display(Dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.interpolate(method = 'spline', order = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "on_thyroxine          0.064826\n",
       "query_hyperthyroid    0.093372\n",
       "tumor                 0.089330\n",
       "TSH                   0.159848\n",
       "T3                    0.122522\n",
       "TT4                   0.057923\n",
       "FTI                   0.073765\n",
       "Name: Target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_values = abs(Dataset[Dataset.columns[0:]].corr()['Target'][:])\n",
    "corr_values = corr_values.drop('Target')\n",
    "corr_values = corr_values[corr_values > 0.04]\n",
    "display(corr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout(dataframe):\n",
    "    # Convert Index object to a list of column names\n",
    "    corr_column_names = list(corr_values.index)\n",
    "\n",
    "    # Select relevant columns using the list of names\n",
    "    x = dataframe[corr_column_names]\n",
    "    y = dataframe['Target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Pass the DataFrame object itself, not the dictionary\n",
    "X_train, X_test, y_train, y_test = holdout(Dataset)  # Use Dataset, not data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Support Vector Machine (SVM)\": SVC(),  # Add SVM\n",
    "    \"K-Nearest Neighbor (KNN)\": KNeighborsClassifier(4),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()  # Add Gradient Boosting\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for:  Support Vector Machine (SVM)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2034,    3,    2],\n",
       "       [  89,    0,    0],\n",
       "       [  28,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for:  K-Nearest Neighbor (KNN)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2022,   15,    2],\n",
       "       [  85,    4,    0],\n",
       "       [  28,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for:  Random Forest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1928,   83,   28],\n",
       "       [  71,   18,    0],\n",
       "       [  23,    0,    5]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for:  Gradient Boosting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1961,   58,   20],\n",
       "       [  74,   15,    0],\n",
       "       [  27,    0,    1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FScore</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.4343</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.4277</td>\n",
       "      <td>0.4421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3941</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>0.4014</td>\n",
       "      <td>0.3887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3476</th>\n",
       "      <td>K-Nearest Neighbor (KNN)</td>\n",
       "      <td>0.9397</td>\n",
       "      <td>0.3859</td>\n",
       "      <td>0.3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3236</th>\n",
       "      <td>Support Vector Machine (SVM)</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.3325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Classifier  Accuracy  Precision  Recall\n",
       "FScore                                                           \n",
       "0.4343                 Random Forest    0.9049     0.4277  0.4421\n",
       "0.3941             Gradient Boosting    0.9170     0.4014  0.3887\n",
       "0.3476      K-Nearest Neighbor (KNN)    0.9397     0.3859  0.3455\n",
       "0.3236  Support Vector Machine (SVM)    0.9434     0.3152  0.3325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classification(classifiers, X_train, X_test, y_train, y_test):\n",
    "    # Create an empty list to store results\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        pr, rc, fs, sup = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "        # Create a dictionary of results for each classifier\n",
    "        result_dict = {\n",
    "            \"Classifier\": name,\n",
    "            \"Accuracy\": round(metrics.accuracy_score(y_test, y_pred), 4),\n",
    "            \"Precision\": round(pr, 4),\n",
    "            \"Recall\": round(rc, 4),\n",
    "            \"FScore\": round(fs, 4)\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the results list\n",
    "        results.append(result_dict)\n",
    "\n",
    "        print(\"Confusion matrix for: \", name)\n",
    "        display(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Create the DataFrame from the list of results\n",
    "    res = pd.DataFrame(results)\n",
    "\n",
    "    # Set index and sort\n",
    "    res.set_index(\"FScore\", inplace=True)\n",
    "    res.sort_values(by=\"FScore\", ascending=False, inplace=True)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "display(classification(classifiers, X_train, X_test, y_train, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
